# ComfyUI_HunyuanAvatar_Sm
* [HunyuanVideo-Avatar](https://github.com/Tencent-Hunyuan/HunyuanVideo-Avatar): High-Fidelity Audio-Driven Human Animation for Multiple Characters,try it in comfyUI ,if your VRAM >24G

TIPS:
-----
* å› ä¸ºæµ‹è¯•çš„æ˜¯cpuå¸è½½æ–¹æ¡ˆï¼Œæ‰€ä»¥å¾ˆå¤§å‡ ç‡ä¼šæŠ¥é”™.ç›®å‰ä¸»è¦å¤„ç†æ•°æ®æ··æ‚ï¼ˆéŸ³é¢‘ã€å›¾ç‰‡ã€textçš„embï¼Œå¤šç§æ¨¡å‹ï¼‰å› ä¸ºcpuå¸è½½å¸¦æ¥çš„å„ç§ä¸å…¼å®¹ï¼Œè®¡åˆ’èƒ½è·‘æ‰ä¸Šäº‘ã€‚
* æµ‹è¯•ç¯å¢ƒ:VRam12Gï¼ŒRam64G,transformerå¿…é¡»æŒ‡å®šç‰ˆæœ¬ï¼Œå¦åˆ™ä¼šæŠ¥é”™ï¼Œè…¾è®¯éƒ½æ²¡æ³•è§£å†³ï¼Œæ‰€ä»¥è€å®åŒ¹é…ã€‚


1.Installation  
-----
In the ./ComfyUI /custom_node directory, run the following:   
```
git clone https://github.com/smthemex/ComfyUI_HunyuanAvatar_Sm.git
```  
  
2.requirements  
----
```
pip install -r requirements.txt
```

3 models 
----
* download files from [tencent/HunyuanVideo-Avatar](https://huggingface.co/tencent/HunyuanVideo-Avatar) 
```
â”œâ”€â”€ ComfyUI/models/HunyuanAvatar/
|   â”œâ”€â”€ det_align/
|         â”œâ”€â”€detface.pt
|   â”œâ”€â”€ llava_llama_image/
|         â”œâ”€â”€config.json
|         â”œâ”€â”€ ...æ‰€æœ‰jsonæ–‡ä»¶ä»¥åŠæ‰€æœ‰safetensorsæ¨¡å‹
|   â”œâ”€â”€text_encoder_2/
|         â”œâ”€â”€config.json
|         â”œâ”€â”€ ... æ‰€æœ‰jsonæ–‡ä»¶ä»¥åŠmodel.safetensorsæ¨¡å‹
|   â”œâ”€â”€vae/
|         â”œâ”€â”€config.json
|         â”œâ”€â”€ pytorch_model.pt
|   â”œâ”€â”€whisper-tiny/
|         â”œâ”€â”€config.json
|         â”œâ”€â”€ ... æ‰€æœ‰jsonæ–‡ä»¶ä»¥åŠmodel.safetensorsæ¨¡å‹
|   â”œâ”€â”€ mp_rank_00_model_states_fp8_map.pt #104K
|   â”œâ”€â”€ mp_rank_00_model_states_fp8.pt.pt #24.9G
```
4 example
----
![](https://github.com/smthemex/ComfyUI_HunyuanAvatar_Sm/blob/main/example_workflows/example.png)


## ğŸ”— BibTeX

If you find [HunyuanVideo-Avatar](https://arxiv.org/pdf/2505.20156) useful for your research and applications, please cite using this BibTeX:

```BibTeX
@misc{hu2025HunyuanVideo-Avatar,
      title={HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters}, 
      author={Yi Chen and Sen Liang and Zixiang Zhou and Ziyao Huang and Yifeng Ma and Junshu Tang and Qin Lin and Yuan Zhou and Qinglin Lu},
      year={2025},
      eprint={2505.20156},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/pdf/2505.20156}, 
}
```

## Acknowledgements

We would like to thank the contributors to the [HunyuanVideo](https://github.com/Tencent/HunyuanVideo), [SD3](https://huggingface.co/stabilityai/stable-diffusion-3-medium), [FLUX](https://github.com/black-forest-labs/flux), [Llama](https://github.com/meta-llama/llama), [LLaVA](https://github.com/haotian-liu/LLaVA), [Xtuner](https://github.com/InternLM/xtuner), [diffusers](https://github.com/huggingface/diffusers) and [HuggingFace](https://huggingface.co) repositories, for their open research and exploration. 
